<h1>Your arXiv Feed for February 07, 2025 (6 Articles)</h1>
<h2>Electrical Impedance Tomography for Anisotropic Media: a Machine Learning Approach to Classify Inclusions</h2>
<h3>Romina Gaburro, Patrick Healy, Shraddha Naidu, Clifford Nolan</h3>
<p>arXiv:2502.04273v1 Announce Type: new 
Abstract: We consider the problem in Electrical Impedance Tomography (EIT) of identifying one or multiple inclusions in a background-conducting body $\Omega\subset\mathbb{R}^2$, from the knowledge of a finite number of electrostatic measurements taken on its boundary $\partial\Omega$ and modelled by the Dirichlet-to-Neumann (D-N) matrix. Once the presence of one inclusion in $\Omega$ is established, our model, combined with the machine learning techniques of Artificial Neural Networks (ANN) and Support Vector Machines (SVM), may be used to determine the size of the inclusion, the presence of multiple inclusions, and also that of anisotropy within the inclusion(s). Utilising both real and simulated datasets within a 16-electrode setup, we achieve a high rate of inclusion detection and show that two measurements are sufficient to achieve a good level of accuracy when predicting the size of an inclusion. This underscores the substantial potential of integrating machine learning approaches with the more classical analysis of EIT and the inverse inclusion problem to extract critical insights, such as the presence of anisotropy.</p>
<a href='https://arxiv.org/abs/2502.04273'>ArXiv Link</a>

<h2>Negative Moment Bounds for Sample Autocovariance Matrices of Stationary Processes Driven by Conditional Heteroscedastic Errors and Their Applications</h2>
<h3>Hsueh-Han Huang, Shu-Hui Yu, Ching-Kang Ing</h3>
<p>arXiv:2301.07476v3 Announce Type: replace 
Abstract: We establish a negative moment bound for the sample autocovariance matrix of a stationary process driven by conditional heteroscedastic errors. This moment bound enables us to asymptotically express the mean squared prediction error (MSPE) of the least squares predictor as the sum of three terms related to model complexity, model misspecification, and conditional heteroscedasticity. A direct application of this expression is the development of a model selection criterion that can asymptotically identify the best (in the sense of MSPE) subset AR model in the presence of misspecification and conditional heteroscedasticity. Finally, numerical simulations are conducted to confirm our theoretical results.</p>
<a href='https://arxiv.org/abs/2301.07476'>ArXiv Link</a>

<h2>Bifurcation Analysis of Predator-Prey System using Conformable Fractional Order Discretization</h2>
<h3>Muhammad Rafaqat, Abubakar Masha, Nauman Ahmed, Ali Raza, Wojciech Sumelka</h3>
<p>arXiv:2501.02386v2 Announce Type: replace 
Abstract: In this paper, conformal fractional order discretization [20, 24, 25] is used to analyze bifurcation analysis and stability of a predator-prey system. A continuous model has been discretized into a discrete one while preserving the fractional-order dynamics. This allows us to look more closely at the stability properties of the system and bifurcation phenomena, including period-doubling and Neimark-Sacker bifurcation. Through numerical and theoretical methods, this research investigated how the modification in system parameters affects the overall dynamics, which may have implications for ecological management and conservation strategies.</p>
<a href='https://arxiv.org/abs/2501.02386'>ArXiv Link</a>

<h2>Gold-medalist Performance in Solving Olympiad Geometry with AlphaGeometry2</h2>
<h3>Yuri Chervonyi, Trieu H. Trinh, Miroslav Ol\v{s}\'ak, Xiaomeng Yang, Hoang Nguyen, Marcelo Menegali, Junehyuk Jung, Vikas Verma, Quoc V. Le, Thang Luong</h3>
<p>arXiv:2502.03544v1 Announce Type: new 
Abstract: We present AlphaGeometry2, a significantly improved version of AlphaGeometry introduced in Trinh et al. (2024), which has now surpassed an average gold medalist in solving Olympiad geometry problems. To achieve this, we first extend the original AlphaGeometry language to tackle harder problems involving movements of objects, and problems containing linear equations of angles, ratios, and distances. This, together with other additions, has markedly improved the coverage rate of the AlphaGeometry language on International Math Olympiads (IMO) 2000-2024 geometry problems from 66% to 88%. The search process of AlphaGeometry2 has also been greatly improved through the use of Gemini architecture for better language modeling, and a novel knowledge-sharing mechanism that combines multiple search trees. Together with further enhancements to the symbolic engine and synthetic data generation, we have significantly boosted the overall solving rate of AlphaGeometry2 to 84% for $\textit{all}$ geometry problems over the last 25 years, compared to 54% previously. AlphaGeometry2 was also part of the system that achieved silver-medal standard at IMO 2024 https://dpmd.ai/imo-silver. Last but not least, we report progress towards using AlphaGeometry2 as a part of a fully automated system that reliably solves geometry problems directly from natural language input.</p>
<a href='https://arxiv.org/abs/2502.03544'>ArXiv Link</a>

<h2>Should Code Models Learn Pedagogically? A Preliminary Evaluation of Curriculum Learning for Real-World Software Engineering Tasks</h2>
<h3>Kyi Shin Khant, Hong Yi Lin, Patanamon Thongtanunam</h3>
<p>arXiv:2502.03806v1 Announce Type: new 
Abstract: Learning-based techniques, especially advanced pre-trained models for code have demonstrated capabilities in code understanding and generation, solving diverse software engineering (SE) tasks. Despite the promising results, current training approaches may not fully optimize model performance, as they typically involve learning from randomly shuffled training data. Recent work shows that Curriculum Learning (CL) can improve performance on code-related tasks through incremental learning based on the difficulty of synthetic code. Yet, the effectiveness of CL with conventional difficulty measures in SE tasks remains largely unexplored. In this study, we explore two conventional code metrics: code length and cyclomatic complexity to determine the difficulty levels. We investigate how the pre-trained code model (CodeT5) learns under CL, through the tasks of code clone detection and code summarization. Our empirical study on the CodeXGLUE benchmark showed contrasting results to prior studies, where the model exhibited signs of catastrophic forgetting and shortcut learning. Surprisingly, model performance saturates after only the first quartile of training, potentially indicating a limit in the model's representation capacity and/or the task's inherent difficulty. Future work should further explore various CL strategies with different code models across a wider range of SE tasks for a more holistic understanding.</p>
<a href='https://arxiv.org/abs/2502.03806'>ArXiv Link</a>

<h2>VTutor: An Open-Source SDK for Generative AI-Powered Animated Pedagogical Agents with Multi-Media Output</h2>
<h3>Eason Chen, Chengyu Lin, Xinyi Tang, Aprille Xi, Canwen Wang, Jionghao Lin, Kenneth R Koedinger</h3>
<p>arXiv:2502.04103v1 Announce Type: new 
Abstract: The rapid evolution of large language models (LLMs) has transformed human-computer interaction (HCI), but the interaction with LLMs is currently mainly focused on text-based interactions, while other multi-model approaches remain under-explored. This paper introduces VTutor, an open-source Software Development Kit (SDK) that combines generative AI with advanced animation technologies to create engaging, adaptable, and realistic APAs for human-AI multi-media interactions. VTutor leverages LLMs for real-time personalized feedback, advanced lip synchronization for natural speech alignment, and WebGL rendering for seamless web integration. Supporting various 2D and 3D character models, VTutor enables researchers and developers to design emotionally resonant, contextually adaptive learning agents. This toolkit enhances learner engagement, feedback receptivity, and human-AI interaction while promoting trustworthy AI principles in education. VTutor sets a new standard for next-generation APAs, offering an accessible, scalable solution for fostering meaningful and immersive human-AI interaction experiences. The VTutor project is open-sourced and welcomes community-driven contributions and showcases.</p>
<a href='https://arxiv.org/abs/2502.04103'>ArXiv Link</a>

