<h1>Your arXiv Feed for September 16, 2025 (6 Articles)</h1>
<h2>Journey of Lars Ahlfors' Fields Medal</h2>
<h3>Frank Wang</h3>
<p>arXiv:2506.12850v4 Announce Type: replace 
Abstract: This is the story of the first Fields Medal awarded to Lars Ahlfors. It was smuggled out of Finland in 1944, pawned in Sweden during World War II, and returned to Helsinki in 2004. This article is based on an interview with Ahlfors' second daughter Vanessa Gruen, and established biographical sources.</p>
<a href='https://arxiv.org/abs/2506.12850'>ArXiv Link</a>

<h2>Predator-Prey Model: Driven Hunt for Accelerated Grokking</h2>
<h3>I. A. Lopatin, S. V. Kozyrev, A. N. Pechen</h3>
<p>arXiv:2509.10562v1 Announce Type: new 
Abstract: A machine learning method is proposed using two agents that simulate the biological behavior of a predator and a prey. In this method, the predator and the prey interact with each other - the predator chases the prey while the prey runs away from the predator - to perform an optimization on the landscape. This method allows, for the case of a ravine landscape (i.e., a landscape with narrow ravines and with gentle slopes along the ravines) to avoid getting optimization stuck in the ravine. For this, in the optimization over a ravine landscape the predator drives the prey along the ravine. Thus we also call this approach, for the case of ravine landscapes, the driven hunt method. For some examples of grokking (i.e., delayed generalization) problems we show that this method allows for achieving up to a hundred times faster learning compared to the standard learning procedure.</p>
<a href='https://arxiv.org/abs/2509.10562'>ArXiv Link</a>

<h2>FR-Net: Learning Robust Quadrupedal Fall Recovery on Challenging Terrains through Mass-Contact Prediction</h2>
<h3>Yidan Lu, Yinzhao Dong, Jiahui Zhang, Ji Ma, Peng Lu</h3>
<p>arXiv:2509.11504v1 Announce Type: new 
Abstract: Fall recovery for legged robots remains challenging, particularly on complex terrains where traditional controllers fail due to incomplete terrain perception and uncertain interactions. We present \textbf{FR-Net}, a learning-based framework that enables quadrupedal robots to recover from arbitrary fall poses across diverse environments. Central to our approach is a Mass-Contact Predictor network that estimates the robot's mass distribution and contact states from limited sensory inputs, facilitating effective recovery strategies. Our carefully designed reward functions ensure safe recovery even on steep stairs without dangerous rolling motions common to existing methods. Trained entirely in simulation using privileged learning, our framework guides policy learning without requiring explicit terrain data during deployment. We demonstrate the generalization capabilities of \textbf{FR-Net} across different quadrupedal platforms in simulation and validate its performance through extensive real-world experiments on the Go2 robot in 10 challenging scenarios. Our results indicate that explicit mass-contact prediction is key to robust fall recovery, offering a promising direction for generalizable quadrupedal skills.</p>
<a href='https://arxiv.org/abs/2509.11504'>ArXiv Link</a>

<h2>Exploring Conversational Design Choices in LLMs for Pedagogical Purposes: Socratic and Narrative Approaches for Improving Instructor's Teaching Practice</h2>
<h3>Si Chen, Isabel R. Molnar, Peiyu Li, Adam Acunin, Ting Hua, Alex Ambrose, Nitesh V. Chawla, Ronald Metoyer</h3>
<p>arXiv:2509.12107v1 Announce Type: new 
Abstract: Large language models (LLMs) typically generate direct answers, yet they are increasingly used as learning tools. Studying instructors' usage is critical, given their role in teaching and guiding AI adoption in education. We designed and evaluated TeaPT, an LLM for pedagogical purposes that supports instructors' professional development through two conversational approaches: a Socratic approach that uses guided questioning to foster reflection, and a Narrative approach that offers elaborated suggestions to extend externalized cognition. In a mixed-method study with 41 higher-education instructors, the Socratic version elicited greater engagement, while the Narrative version was preferred for actionable guidance. Subgroup analyses further revealed that less-experienced, AI-optimistic instructors favored the Socratic version, whereas more-experienced, AI-cautious instructors preferred the Narrative version. We contribute design implications for LLMs for pedagogical purposes, showing how adaptive conversational approaches can support instructors with varied profiles while highlighting how AI attitudes and experience shape interaction and learning.</p>
<a href='https://arxiv.org/abs/2509.12107'>ArXiv Link</a>

<h2>Standing Tall: Robust Fall Prediction for Bipedal Robots</h2>
<h3>Gokul Prabhakaran, Jessy W. Grizzle, M. Eva Mungai</h3>
<p>arXiv:2506.01141v2 Announce Type: replace 
Abstract: This paper extends the fall prediction algorithm from Mungai et al.(2024) to a real-time/online setting, implemented in both hardware and simulation. This yields results comparable to the offline version, maintaining a zero false positive rate, sufficient lead time, and accurate lead time prediction. Additionally, it achieves a high recovery rate. The paper also evaluates the fall prediction algorithm against omnidirectional faults and introduces an improved algorithm capable of reliably predicting falls and lead times across a wider range of faults in full-sized robots. Compared to Mungai et al.(2024), the proposed algorithm performs significantly better across all metrics, such as false positive rate, lead time, accuracy, and response time, demonstrating the algorithm's efficacy for real-time fall prediction in bipedal robots.</p>
<a href='https://arxiv.org/abs/2506.01141'>ArXiv Link</a>

<h2>Acrobotics: A Generalist Approach to Quadrupedal Robots' Parkour</h2>
<h3>Guillaume Gagn\'e-Labelle, Vassil Atanassov, Ioannis Havoutis</h3>
<p>arXiv:2509.02727v2 Announce Type: replace 
Abstract: Climbing, crouching, bridging gaps, and walking up stairs are just a few of the advantages that quadruped robots have over wheeled robots, making them more suitable for navigating rough and unstructured terrain. However, executing such manoeuvres requires precise temporal coordination and complex agent-environment interactions. Moreover, legged locomotion is inherently more prone to slippage and tripping, and the classical approach of modeling such cases to design a robust controller thus quickly becomes impractical. In contrast, reinforcement learning offers a compelling solution by enabling optimal control through trial and error. We present a generalist reinforcement learning algorithm for quadrupedal agents in dynamic motion scenarios. The learned policy rivals state-of-the-art specialist policies trained using a mixture of experts approach, while using only 25% as many agents during training. Our experiments also highlight the key components of the generalist locomotion policy and the primary factors contributing to its success.</p>
<a href='https://arxiv.org/abs/2509.02727'>ArXiv Link</a>

