<h1>Your arXiv Feed for April 09, 2025 (3 Articles)</h1>
<h2>Learning-enhanced electronic skin for tactile sensing on deformable surface based on electrical impedance tomography</h2>
<h3>Huazhi Dong, Xiaopeng Wu, Delin Hu, Zhe Liu, Francesco Giorgio-Serchi, Yunjie Yang</h3>
<p>arXiv:2504.05987v1 Announce Type: new 
Abstract: Electrical Impedance Tomography (EIT)-based tactile sensors offer cost-effective and scalable solutions for robotic sensing, especially promising for soft robots. However a major issue of EIT-based tactile sensors when applied in highly deformable objects is their performance degradation due to surface deformations. This limitation stems from their inherent sensitivity to strain, which is particularly exacerbated in soft bodies, thus requiring dedicated data interpretation to disentangle the parameter being measured and the signal deriving from shape changes. This has largely limited their practical implementations. This paper presents a machine learning-assisted tactile sensing approach to address this challenge by tracking surface deformations and segregating this contribution in the signal readout during tactile sensing. We first capture the deformations of the target object, followed by tactile reconstruction using a deep learning model specifically designed to process and fuse EIT data and deformation information. Validations using numerical simulations achieved high correlation coefficients (0.9660 - 0.9999), peak signal-to-noise ratios (28.7221 - 55.5264 dB) and low relative image errors (0.0107 - 0.0805). Experimental validations, using a hydrogel-based EIT e-skin under various deformation scenarios, further demonstrated the effectiveness of the proposed approach in real-world settings. The findings could underpin enhanced tactile interaction in soft and highly deformable robotic applications.</p>
<a href='https://arxiv.org/abs/2504.05987'>ArXiv Link</a>

<h2>Accessible and Pedagogically-Grounded Explainability for Human-Robot Interaction: A Framework Based on UDL and Symbolic Interfaces</h2>
<h3>Francisco J. Rodr\'iguez Lera, Raquel Fern\'andez Hern\'andez, Sonia Lopez Gonz\'alez, Miguel Angel Gonz\'alez-Santamarta, Francisco Jes\'us Rodr\'iguez Sedano, Camino Fernandez Llamas</h3>
<p>arXiv:2504.06189v1 Announce Type: new 
Abstract: This paper presents a novel framework for accessible and pedagogically-grounded robot explainability, designed to support human-robot interaction (HRI) with users who have diverse cognitive, communicative, or learning needs. We combine principles from Universal Design for Learning (UDL) and Universal Design (UD) with symbolic communication strategies to facilitate the alignment of mental models between humans and robots. Our approach employs Asterics Grid and ARASAAC pictograms as a multimodal, interpretable front-end, integrated with a lightweight HTTP-to-ROS 2 bridge that enables real-time interaction and explanation triggering. We emphasize that explainability is not a one-way function but a bidirectional process, where human understanding and robot transparency must co-evolve. We further argue that in educational or assistive contexts, the role of a human mediator (e.g., a teacher) may be essential to support shared understanding. We validate our framework with examples of multimodal explanation boards and discuss how it can be extended to different scenarios in education, assistive robotics, and inclusive AI.</p>
<a href='https://arxiv.org/abs/2504.06189'>ArXiv Link</a>

<h2>Improving Privacy Benefits of Redaction</h2>
<h3>Vaibhav Gusain, Douglas Leith</h3>
<p>arXiv:2501.17762v3 Announce Type: replace 
Abstract: We propose a novel redaction methodology that can be used to sanitize natural text data. Our new technique provides better privacy benefits than other state of the art techniques while maintaining lower redaction levels.</p>
<a href='https://arxiv.org/abs/2501.17762'>ArXiv Link</a>

