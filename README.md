<h1>Your arXiv Feed for November 28, 2024 (2 Articles)</h1>
<h2>Singular bifurcations in a slow-fast modified Leslie-Gower model with Holling type II functional response, weak Allee effect and a generalist predator</h2>
<h3>Roberto Albarran Garc\'ia, Martha Alvarez-Ram\'irez, Hildeberto Jard\'on-Kojakhmetov</h3>
<p>arXiv:2411.18059v1 Announce Type: new 
Abstract: We study a predator-prey system with a generalist Leslie-Gower predator, a functional Holling type II response, and a weak Allee effect on the prey. The prey's population often grows much faster than its predator, allowing us to introduce a small time scale parameter $\varepsilon$ that relates the growth rates of both species, giving rise to a slow-fast system. Zhu and Liu (2022) show that, in the case of the weak Allee effect, Hopf singular bifurcation, slow-fast canard cycles, relaxation oscillations, etc., exist. Our main contribution lies in the rigorous analysis of a degenerate scenario organized by a (degenerate) transcritical bifurcation. The key tool employed is the blow-up method that desingularizes the degenerate singularity. In addition, we determine the criticality of the singular Hopf bifurcation using recent intrinsic techniques that do not require a local normal form. The theoretical analysis is complemented by a numerical bifurcation analysis, in which we numerically identify and analytically confirm the existence of a nearby Takens-Bogdanov point.</p>
<a href='https://arxiv.org/abs/2411.18059'>ArXiv Link</a>

<h2>cedar: Optimized and Unified Machine Learning Input Data Pipelines</h2>
<h3>Mark Zhao, Emanuel Adamiak, Christos Kozyrakis</h3>
<p>arXiv:2401.08895v4 Announce Type: replace 
Abstract: The input data pipeline is an essential component of each machine learning (ML) training job. It is responsible for reading massive amounts of training data, processing batches of samples using complex transformations, and loading them onto training nodes at low latency and high throughput. Performant input data systems are becoming increasingly critical, driven by skyrocketing data volumes and training throughput demands. Unfortunately, current input data systems cannot fully leverage key performance optimizations, resulting in hugely inefficient infrastructures that require significant resources - or worse - underutilize expensive accelerators.
  To address these demands, we present cedar, an optimized and unified programming framework for ML input data pipelines. cedar allows users to define input data pipelines using composable operators that support arbitrary ML frameworks and libraries. cedar introduces an extensible optimizer that systematically applies a complex combination of optimizations (e.g., offloading, caching, prefetching, fusion, and reordering). It orchestrates processing across a customizable set of local and distributed compute resources in order to improve processing performance and efficiency, all without user input. Across eight pipelines, cedar improves performance by up to 1.87x to 10.65x compared to state-of-the-art input data systems.</p>
<a href='https://arxiv.org/abs/2401.08895'>ArXiv Link</a>

