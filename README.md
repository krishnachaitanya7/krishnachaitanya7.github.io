<h1>Your arXiv Feed for January 28, 2025 (3 Articles)</h1>
<h2>SedarEval: Automated Evaluation using Self-Adaptive Rubrics</h2>
<h3>Zhiyuan Fan, Weinong Wang, Xing Wu, Debing Zhang</h3>
<p>arXiv:2501.15595v1 Announce Type: new 
Abstract: The evaluation paradigm of LLM-as-judge gains popularity due to its significant reduction in human labor and time costs. This approach utilizes one or more large language models (LLMs) to assess the quality of outputs from other LLMs. However, existing methods rely on generic scoring rubrics that fail to consider the specificities of each question and its problem-solving process, compromising precision and stability in assessments. Inspired by human examination scoring processes, we propose a new evaluation paradigm based on self-adaptive rubrics. Specifically, we create detailed scoring rubrics for each question, capturing the primary and secondary criteria in a structured format of scoring and deduction points that mimic a human evaluator's analytical process. Building on this paradigm, we further develop a novel benchmark called SedarEval, which covers a range of domains including long-tail knowledge, mathematics, coding, and logical reasoning. SedarEval consists of 1,000 meticulously crafted questions, each with its own self-adaptive rubric. To further streamline the evaluation, we train a specialized evaluator language model (evaluator LM) to supplant human graders. Using the same training data, our evaluator LM achieves a higher concordance rate with human grading results than other paradigms, including GPT-4, highlighting the superiority and efficiency of our approach. We release our dataset at https://github.com/wwn1233/sedareval.</p>
<a href='https://arxiv.org/abs/2501.15595'>ArXiv Link</a>

<h2>CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks</h2>
<h3>Kaizheng Wang, Keivan Shariatmadar, Shireen Kudukkil Manchingal, Fabio Cuzzolin, David Moens, Hans Hallez</h3>
<p>arXiv:2401.05043v3 Announce Type: replace 
Abstract: Effective uncertainty estimation is becoming increasingly attractive for enhancing the reliability of neural networks. This work presents a novel approach, termed Credal-Set Interval Neural Networks (CreINNs), for classification. CreINNs retain the fundamental structure of traditional Interval Neural Networks, capturing weight uncertainty through deterministic intervals. CreINNs are designed to predict an upper and a lower probability bound for each class, rather than a single probability value. The probability intervals can define a credal set, facilitating estimating different types of uncertainties associated with predictions. Experiments on standard multiclass and binary classification tasks demonstrate that the proposed CreINNs can achieve superior or comparable quality of uncertainty estimation compared to variational Bayesian Neural Networks (BNNs) and Deep Ensembles. Furthermore, CreINNs significantly reduce the computational complexity of variational BNNs during inference. Moreover, the effective uncertainty quantification of CreINNs is also verified when the input data are intervals.</p>
<a href='https://arxiv.org/abs/2401.05043'>ArXiv Link</a>

<h2>Clustering of functional data prone to complex heteroscedastic measurement error</h2>
<h3>Andi Mai, Carmen Tekwe, Roger Zoh, Lan Xue</h3>
<p>arXiv:2501.14919v1 Announce Type: new 
Abstract: Several factors make clustering of functional data challenging, including the infinite-dimensional space to which observations belong and the lack of a defined probability density function for the functional random variable. To overcome these barriers, researchers either assume that observations belong to a finite-dimensional space spanned by basis functions or apply nonparametric smoothing methods to the functions prior to clustering. Although extensive literature describes clustering methods for functional data, few studies have explored the clustering of measurement error--prone function-valued data. In this work, we consider clustering methods for functional data prone to complex, heteroscedastic measurement errors. Two stage-based methods using mixed-effects models are first applied to adjust for measurement error bias, followed by cluster analysis of the measurement error--adjusted curves. Through simulations, we investigate how varying sample size, the magnitude of measurement error, and the presence of complex heteroscedastic measurement errors influence the cluster analysis of functional data. Our results indicate that failing to account for measurement errors and the correlation structures associated with frequently collected functional data reduces the accuracy of identifying the true latent groups or clusters. The method consistently produces better results regardless of the initial clustering values used. Moreover, it is flexible and can be applied to various clustering approaches, based on the specific distribution of the data. The developed methods are applied to two data sets: a school-based study of energy expenditure among elementary school-aged children in Texas and data from the National Health and Nutrition Examination Survey on participants' physical activity monitored by wearable devices at frequent intervals.</p>
<a href='https://arxiv.org/abs/2501.14919'>ArXiv Link</a>

