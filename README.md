<h1>Your arXiv Feed for October 25, 2024 (2 Articles)</h1>
<h2>Credal Learning Theory</h2>
<h3>Michele Caprio, Maryam Sultana, Eleni Elia, Fabio Cuzzolin</h3>
<p>arXiv:2402.00957v4 Announce Type: replace 
Abstract: Statistical learning theory is the foundation of machine learning, providing theoretical bounds for the risk of models learned from a (single) training set, assumed to issue from an unknown probability distribution. In actual deployment, however, the data distribution may (and often does) vary, causing domain adaptation/generalization issues. In this paper we lay the foundations for a `credal' theory of learning, using convex sets of probabilities (credal sets) to model the variability in the data-generating distribution. Such credal sets, we argue, may be inferred from a finite sample of training sets. Bounds are derived for the case of finite hypotheses spaces (both assuming realizability or not), as well as infinite model spaces, which directly generalize classical results.</p>
<a href='https://arxiv.org/abs/2402.00957'>ArXiv Link</a>

<h2>SSP-RACL: Classification of Noisy Fundus Images with Self-Supervised Pretraining and Robust Adaptive Credal Loss</h2>
<h3>Mengwen Ye, Yingzi Huangfu, You Li, Zekuan Yu</h3>
<p>arXiv:2409.18147v3 Announce Type: replace 
Abstract: Fundus image classification is crucial in the computer aided diagnosis tasks, but label noise significantly impairs the performance of deep neural networks. To address this challenge, we propose a robust framework, Self-Supervised Pre-training with Robust Adaptive Credal Loss (SSP-RACL), for handling label noise in fundus image datasets. First, we use Masked Autoencoders (MAE) for pre-training to extract features, unaffected by label noise. Subsequently, RACL employ a superset learning framework, setting confidence thresholds and adaptive label relaxation parameter to construct possibility distributions and provide more reliable ground-truth estimates, thus effectively suppressing the memorization effect. Additionally, we introduce clinical knowledge-based asymmetric noise generation to simulate real-world noisy fundus image datasets. Experimental results demonstrate that our proposed method outperforms existing approaches in handling label noise, showing superior performance.</p>
<a href='https://arxiv.org/abs/2409.18147'>ArXiv Link</a>

