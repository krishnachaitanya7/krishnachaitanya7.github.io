<h1>Your arXiv Feed for March 17, 2025 (3 Articles)</h1>
<h2>Training Directional Locomotion for Quadrupedal Low-Cost Robotic Systems via Deep Reinforcement Learning</h2>
<h3>Peter B\"ohm, Archie C. Chapman, Pauline Pounds</h3>
<p>arXiv:2503.11059v1 Announce Type: new 
Abstract: In this work we present Deep Reinforcement Learning (DRL) training of directional locomotion for low-cost quadrupedal robots in the real world. In particular, we exploit randomization of heading that the robot must follow to foster exploration of action-state transitions most useful for learning both forward locomotion as well as course adjustments. Changing the heading in episode resets to current yaw plus a random value drawn from a normal distribution yields policies able to follow complex trajectories involving frequent turns in both directions as well as long straight-line stretches. By repeatedly changing the heading, this method keeps the robot moving within the training platform and thus reduces human involvement and need for manual resets during the training. Real world experiments on a custom-built, low-cost quadruped demonstrate the efficacy of our method with the robot successfully navigating all validation tests. When trained with other approaches, the robot only succeeds in forward locomotion test and fails when turning is required.</p>
<a href='https://arxiv.org/abs/2503.11059'>ArXiv Link</a>

<h2>A Two-Stage Imaging Framework Combining CNN and Physics-Informed Neural Networks for Full-Inverse Tomography: A Case Study in Electrical Impedance Tomography (EIT)</h2>
<h3>Xuanxuan Yang (the Institute of Intelligent Machines, Chinese Academy of Sciences, University of Science and Technology of China), Yangming Zhang (the Institute of Intelligent Machines, Chinese Academy of Sciences), Haofeng Chen (the Institute of Intelligent Machines, Chinese Academy of Sciences, University of Science and Technology of China), Gang Ma (University of Science and Technology of China), Xiaojie Wang (the Institute of Intelligent Machines, Chinese Academy of Sciences)</h3>
<p>arXiv:2407.17721v2 Announce Type: replace 
Abstract: Electrical Impedance Tomography (EIT) is a highly ill-posed inverse problem, with the challenge of reconstructing internal conductivities using only boundary voltage measurements. Although Physics-Informed Neural Networks (PINNs) have shown potential in solving inverse problems, existing approaches are limited in their applicability to EIT, as they often rely on impractical prior knowledge and assumptions that cannot be satisfied in real-world scenarios. To address these limitations, we propose a two-stage hybrid learning framework that combines Convolutional Neural Networks (CNNs) and PINNs. This framework integrates data-driven and model-driven paradigms, blending supervised and unsupervised learning to reconstruct conductivity distributions while ensuring adherence to the underlying physical laws, thereby overcoming the constraints of existing methods.</p>
<a href='https://arxiv.org/abs/2407.17721'>ArXiv Link</a>

<h2>The Duke Humanoid: Design and Control For Energy Efficient Bipedal Locomotion Using Passive Dynamics</h2>
<h3>Boxi Xia, Bokuan Li, Jacob Lee, Michael Scutari, Boyuan Chen</h3>
<p>arXiv:2409.19795v2 Announce Type: replace 
Abstract: We present the Duke Humanoid, an open-source 10-degrees-of-freedom humanoid, as an extensible platform for locomotion research. The design mimics human physiology, with symmetrical body alignment in the frontal plane to maintain static balance with straight knees. We develop a reinforcement learning policy that can be deployed zero-shot on the hardware for velocity-tracking walking tasks. Additionally, to enhance energy efficiency in locomotion, we propose an end-to-end reinforcement learning algorithm that encourages the robot to leverage passive dynamics. Our experimental results show that our passive policy reduces the cost of transport by up to $50\%$ in simulation and $31\%$ in real-world tests. Our website is http://generalroboticslab.com/DukeHumanoidv1/ .</p>
<a href='https://arxiv.org/abs/2409.19795'>ArXiv Link</a>

