<h1>Your arXiv Feed for November 22, 2024 (4 Articles)</h1>
<h2>Filtering and Statistical Properties of Unimodal Maps Perturbed by Heteroscedastic Noises</h2>
<h3>Fabrizio Lillo, Stefano Marmi, Matteo Tanzi, Sandro Vaienti</h3>
<p>arXiv:2411.13939v1 Announce Type: new 
Abstract: We propose a theory of unimodal maps perturbed by an heteroscedastic Markov chain noise and experiencing another heteroscedastic noise due to uncertain observation. We address and treat the filtering problem showing that by collecting more and more observations, one would predict the same distribution for the state of the underlying Markov chain no matter one's initial guess. Moreover we give other limit theorems, emphasizing in particular concentration inequalities and extreme value and Poisson distributions. Our results apply to a family of maps arising from a model of systemic risk in finance.</p>
<a href='https://arxiv.org/abs/2411.13939'>ArXiv Link</a>

<h2>Hierarchical Text Classification (HTC) vs. eXtreme Multilabel Classification (XML): Two Sides of the Same Medal</h2>
<h3>Nerijus Bertalis, Paul Granse, Ferhat G\"ul, Florian Hauss, Leon Menkel, David Sch\"uler, Tom Speier, Lukas Galke, Ansgar Scherp</h3>
<p>arXiv:2411.13687v1 Announce Type: new 
Abstract: Assigning a subset of labels from a fixed pool of labels to a given input text is a text classification problem with many real-world applications, such as in recommender systems. Two separate research streams address this issue. Hierarchical Text Classification (HTC) focuses on datasets with smaller label pools of hundreds of entries, accompanied by a semantic label hierarchy. In contrast, eXtreme Multi-Label Text Classification (XML) considers very large label pools with up to millions of entries, in which the labels are not arranged in any particular manner. However, in XML, a common approach is to construct an artificial hierarchy without any semantic information before or during the training process. Here, we investigate how state-of-the-art models from one domain perform when trained and tested on datasets from the other domain. The HBGL and HGLCR models from the HTC domain are trained and tested on the datasets Wiki10-31K, AmazonCat-13K, and Amazon-670K from the XML domain. On the other side, the XML models CascadeXML and XR-Transformer are trained and tested on the datasets Web of Science, The New York Times Annotated Corpus, and RCV1-V2 from the HTC domain. HTC models, on the other hand, are not equipped to handle the size of XML datasets and achieve poor transfer results. The code and numerous files that are needed to reproduce our results can be obtained from https://github.com/FloHauss/XMC_HTC</p>
<a href='https://arxiv.org/abs/2411.13687'>ArXiv Link</a>

<h2>GNN-MultiFix: Addressing the pitfalls for GNNs for multi-label node classification</h2>
<h3>Tianqi Zhao, Megha Khosla</h3>
<p>arXiv:2411.14094v1 Announce Type: new 
Abstract: Graph neural networks (GNNs) have emerged as powerful models for learning representations of graph data showing state of the art results in various tasks. Nevertheless, the superiority of these methods is usually supported by either evaluating their performance on small subset of benchmark datasets or by reasoning about their expressive power in terms of certain graph isomorphism tests. In this paper we critically analyse both these aspects through a transductive setting for the task of node classification. First, we delve deeper into the case of multi-label node classification which offers a more realistic scenario and has been ignored in most of the related works. Through analysing the training dynamics for GNN methods we highlight the failure of GNNs to learn over multi-label graph datasets even for the case of abundant training data. Second, we show that specifically for transductive node classification, even the most expressive GNN may fail to learn in absence of node attributes and without using explicit label information as input. To overcome this deficit, we propose a straightforward approach, referred to as GNN-MultiFix, that integrates the feature, label, and positional information of a node. GNN-MultiFix demonstrates significant improvement across all the multi-label datasets. We release our code at https://anonymous.4open.science/r/Graph-MultiFix-4121.</p>
<a href='https://arxiv.org/abs/2411.14094'>ArXiv Link</a>

<h2>Large-scale cross-modality pretrained model enhances cardiovascular state estimation and cardiomyopathy detection from electrocardiograms: An AI system development and multi-center validation study</h2>
<h3>Zhengyao Ding, Yujian Hu, Youyao Xu, Chengchen Zhao, Ziyu Li, Yiheng Mao, Haitao Li, Qian Li, Jing Wang, Yue Chen, Mengjia Chen, Longbo Wang, Xuesen Chu, Weichao Pan, Ziyi Liu, Fei Wu, Hongkun Zhang, Ting Chen, Zhengxing Huang</h3>
<p>arXiv:2411.13602v1 Announce Type: cross 
Abstract: Cardiovascular diseases (CVDs) present significant challenges for early and accurate diagnosis. While cardiac magnetic resonance imaging (CMR) is the gold standard for assessing cardiac function and diagnosing CVDs, its high cost and technical complexity limit accessibility. In contrast, electrocardiography (ECG) offers promise for large-scale early screening. This study introduces CardiacNets, an innovative model that enhances ECG analysis by leveraging the diagnostic strengths of CMR through cross-modal contrastive learning and generative pretraining. CardiacNets serves two primary functions: (1) it evaluates detailed cardiac function indicators and screens for potential CVDs, including coronary artery disease, cardiomyopathy, pericarditis, heart failure and pulmonary hypertension, using ECG input; and (2) it enhances interpretability by generating high-quality CMR images from ECG data. We train and validate the proposed CardiacNets on two large-scale public datasets (the UK Biobank with 41,519 individuals and the MIMIC-IV-ECG comprising 501,172 samples) as well as three private datasets (FAHZU with 410 individuals, SAHZU with 464 individuals, and QPH with 338 individuals), and the findings demonstrate that CardiacNets consistently outperforms traditional ECG-only models, substantially improving screening accuracy. Furthermore, the generated CMR images provide valuable diagnostic support for physicians of all experience levels. This proof-of-concept study highlights how ECG can facilitate cross-modal insights into cardiac function assessment, paving the way for enhanced CVD screening and diagnosis at a population level.</p>
<a href='https://arxiv.org/abs/2411.13602'>ArXiv Link</a>

